{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Training set: (82332, 45)\n",
      "Dimensions of the Test set: (175341, 45)\n"
     ]
    }
   ],
   "source": [
    "col_names=[\"id\",\"dur\",\"proto\",\"service\",\"state\",\n",
    "           \"spkts\",\"dpkts\",\"sbytes\",\"dbytes\",\"rate\",\n",
    "           \"sttl\",\"dttl\",\"sload\",\"dload\",\"sloss\",\n",
    "           \"dloss\",\"sinpkt\",\"dinpkt\",\"sjit\",\"djit\",\n",
    "           \"swin\",\"stcpb\",\"dtcpb\",\"dwin\",\"tcprtt\",\n",
    "           \"synack\",\"ackdat\",\"smean\",\"dmean\",\"trans_depth\",\n",
    "           \"response_body_len\",\"ct_srv_src\",\"ct_state_ttl\",\"ct_dst_ltm\",\"ct_src_dport_ltm\",\n",
    "           \"ct_dst_sport_ltm\",\"ct_dst_src_ltm\",\"is_ftp_login\",\"ct_ftp_cmd\",\"ct_flw_http_mthd\",\n",
    "           \"ct_src_ltm\",\"ct_srv_dst\",\"is_sm_ips_ports\",\"attack_cat\",\"label\"\n",
    "]\n",
    "\n",
    "df_train=pd.read_csv(\"UNSW_NB15_training-set.csv\",header=None,names=col_names)\n",
    "df_test=pd.read_csv(\"UNSW_NB15_testing-set.csv\",header=None,names=col_names)\n",
    "\n",
    "print('Dimensions of the Training set:',df_train.shape)\n",
    "print('Dimensions of the Test set:',df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>90909.0902</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.0003</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1068</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0051</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>166666.6608</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2126</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0   1  0.000011   udp       -   INT      2      0     496       0   \n",
       "1   2  0.000008   udp       -   INT      2      0    1762       0   \n",
       "2   3  0.000005   udp       -   INT      2      0    1068       0   \n",
       "3   4  0.000006   udp       -   INT      2      0     900       0   \n",
       "4   5  0.000010   udp       -   INT      2      0    2126       0   \n",
       "\n",
       "          rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "0   90909.0902  ...                 1               2             0   \n",
       "1  125000.0003  ...                 1               2             0   \n",
       "2  200000.0051  ...                 1               3             0   \n",
       "3  166666.6608  ...                 1               3             0   \n",
       "4  100000.0025  ...                 1               3             0   \n",
       "\n",
       "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
       "0           0                 0           1           2                0   \n",
       "1           0                 0           1           2                0   \n",
       "2           0                 0           1           3                0   \n",
       "3           0                 0           2           3                0   \n",
       "4           0                 0           2           3                0   \n",
       "\n",
       "   attack_cat  label  \n",
       "0      Normal      0  \n",
       "1      Normal      0  \n",
       "2      Normal      0  \n",
       "3      Normal      0  \n",
       "4      Normal      0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution Training set:\n",
      "Normal            37000\n",
      "Generic           18871\n",
      "Exploits          11132\n",
      "Fuzzers            6062\n",
      "DoS                4089\n",
      "Reconnaissance     3496\n",
      "Analysis            677\n",
      "Backdoor            583\n",
      "Shellcode           378\n",
      "Worms                44\n",
      "Name: attack_cat, dtype: int64\n",
      "\n",
      "Label distribution Test set:\n",
      "Normal            56000\n",
      "Generic           40000\n",
      "Exploits          33393\n",
      "Fuzzers           18184\n",
      "DoS               12264\n",
      "Reconnaissance    10491\n",
      "Analysis           2000\n",
      "Backdoor           1746\n",
      "Shellcode          1133\n",
      "Worms               130\n",
      "Name: attack_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Label distribution Training set:')\n",
    "print(df_train['attack_cat'].value_counts())\n",
    "print()\n",
    "print('Label distribution Test set:')\n",
    "print(df_test['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Feature 'proto' has 131 categories\n",
      "Feature 'service' has 13 categories\n",
      "Feature 'state' has 7 categories\n",
      "Feature 'attack_cat' has 10 categories\n",
      "\n",
      "Distribution of categories in service:\n",
      "-       47153\n",
      "dns     21367\n",
      "http     8287\n",
      "smtp     1851\n",
      "ftp      1552\n",
      "Name: service, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Training set:')\n",
    "for col_name in df_train.columns:\n",
    "    if df_train[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df_train[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "print()\n",
    "print('Distribution of categories in service:')\n",
    "print(df_train['service'].value_counts().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "Feature 'proto' has 133 categories\n",
      "Feature 'service' has 13 categories\n",
      "Feature 'state' has 9 categories\n",
      "Feature 'attack_cat' has 10 categories\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "print('Test set:')\n",
    "for col_name in df_test.columns:\n",
    "    if df_test[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df_test[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "categorical_columns=['proto', 'service', 'state']\n",
    "# insert code to get a list of categorical columns into a variable, categorical_columns\n",
    "categorical_columns=['proto', 'service', 'state'] \n",
    " # Get the categorical values into a 2D numpy array\n",
    "df_train_categorical_values = df_train[categorical_columns]\n",
    "df_test_categorical_values = df_test[categorical_columns]\n",
    "# df_test_categorical_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train dataset\n",
    "get_protocol=sorted(df_train.proto.unique())\n",
    "prefix_protocol = 'protocol_'\n",
    "protocol_dummies=[prefix_protocol + x for x in get_protocol]\n",
    "\n",
    "get_service=sorted(df_train.service.unique())\n",
    "prefix_service = 'service_'\n",
    "service_dummies=[prefix_service + x for x in get_service]\n",
    "\n",
    "get_state=sorted(df_train.state.unique())\n",
    "prefix_state = 'state_'\n",
    "state_dummies=[prefix_state + x for x in get_state]\n",
    "dum_cols=protocol_dummies+service_dummies+state_dummies\n",
    "# print(dum_cols)\n",
    "\n",
    "# for test dataset\n",
    "get_protocol_test=sorted(df_test.proto.unique())\n",
    "protocol_dummies_test=[prefix_protocol + x for x in get_protocol_test]\n",
    "\n",
    "get_state_test=sorted(df_test.state.unique())\n",
    "state_dummies_test=[prefix_state + x for x in get_state_test]\n",
    "dum_cols_test=protocol_dummies_test+service_dummies+state_dummies_test\n",
    "# print(dum_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   proto  service  state\n",
      "0    117        0      4\n",
      "1    117        0      4\n",
      "2    117        0      4\n",
      "3    117        0      4\n",
      "4    117        0      4\n",
      "Train dataset:\n",
      "   proto  service  state\n",
      "0    113        0      2\n",
      "1    113        0      2\n",
      "2    113        0      2\n",
      "3    113        3      2\n",
      "4    113        0      2\n"
     ]
    }
   ],
   "source": [
    "# train dataset\n",
    "df_train_categorical_values_enc=df_train_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "print(df_train_categorical_values_enc.head())\n",
    "\n",
    "# test dataset\n",
    "df_test_categorical_values_enc=df_test_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "print(\"Train dataset:\")\n",
    "print(df_test_categorical_values_enc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashiu\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ashiu\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_3pc</th>\n",
       "      <th>protocol_a/n</th>\n",
       "      <th>protocol_aes-sp3-d</th>\n",
       "      <th>protocol_any</th>\n",
       "      <th>protocol_argus</th>\n",
       "      <th>protocol_aris</th>\n",
       "      <th>protocol_arp</th>\n",
       "      <th>protocol_ax.25</th>\n",
       "      <th>protocol_bbn-rcc</th>\n",
       "      <th>protocol_bna</th>\n",
       "      <th>...</th>\n",
       "      <th>service_snmp</th>\n",
       "      <th>service_ssh</th>\n",
       "      <th>service_ssl</th>\n",
       "      <th>state_ACC</th>\n",
       "      <th>state_CLO</th>\n",
       "      <th>state_CON</th>\n",
       "      <th>state_FIN</th>\n",
       "      <th>state_INT</th>\n",
       "      <th>state_REQ</th>\n",
       "      <th>state_RST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   protocol_3pc  protocol_a/n  protocol_aes-sp3-d  protocol_any  \\\n",
       "0           0.0           0.0                 0.0           0.0   \n",
       "1           0.0           0.0                 0.0           0.0   \n",
       "2           0.0           0.0                 0.0           0.0   \n",
       "3           0.0           0.0                 0.0           0.0   \n",
       "4           0.0           0.0                 0.0           0.0   \n",
       "\n",
       "   protocol_argus  protocol_aris  protocol_arp  protocol_ax.25  \\\n",
       "0             0.0            0.0           0.0             0.0   \n",
       "1             0.0            0.0           0.0             0.0   \n",
       "2             0.0            0.0           0.0             0.0   \n",
       "3             0.0            0.0           0.0             0.0   \n",
       "4             0.0            0.0           0.0             0.0   \n",
       "\n",
       "   protocol_bbn-rcc  protocol_bna  ...  service_snmp  service_ssh  \\\n",
       "0               0.0           0.0  ...           0.0          0.0   \n",
       "1               0.0           0.0  ...           0.0          0.0   \n",
       "2               0.0           0.0  ...           0.0          0.0   \n",
       "3               0.0           0.0  ...           0.0          0.0   \n",
       "4               0.0           0.0  ...           0.0          0.0   \n",
       "\n",
       "   service_ssl  state_ACC  state_CLO  state_CON  state_FIN  state_INT  \\\n",
       "0          0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "1          0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "2          0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "3          0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "4          0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "\n",
       "   state_REQ  state_RST  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        0.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "df_train_categorical_values_encenc = ohe.fit_transform(df_train_categorical_values_enc)\n",
    "df_train_cat_data = pd.DataFrame(df_train_categorical_values_encenc.toarray(),columns=dum_cols)\n",
    "# test set\n",
    "df_test_categorical_values_encenc = ohe.fit_transform(df_test_categorical_values_enc)\n",
    "df_test_cat_data = pd.DataFrame(df_test_categorical_values_encenc.toarray(),columns=dum_cols_test)\n",
    "\n",
    "df_train_cat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_URN',\n",
       " 'state_ECO',\n",
       " 'state_no',\n",
       " 'state_PAR',\n",
       " 'protocol_rtp',\n",
       " 'protocol_icmp']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_state=df_train['state'].tolist()\n",
    "test_state= df_test['state'].tolist()\n",
    "\n",
    "differences_state=list(set(test_state) - set(train_state))\n",
    "prefix_state = 'state_'\n",
    "differences1=[prefix_state + x for x in differences_state]\n",
    "\n",
    "train_proto=df_train['proto'].tolist()\n",
    "test_proto=df_test['proto'].tolist()\n",
    "differences_proto=list(set(test_proto) - set(train_proto))\n",
    "prefix_protocol = 'protocol_'\n",
    "differences2=[prefix_protocol + x for x in differences_proto]\n",
    "\n",
    "differences=differences1+differences2\n",
    "differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82332, 157)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for difference in differences:\n",
    "    df_train_cat_data[difference] = 0\n",
    "\n",
    "df_train_cat_data.shape\n",
    "# print(df_train_cat_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Normal\n",
      "1        Normal\n",
      "2        Normal\n",
      "3        Normal\n",
      "4        Normal\n",
      "          ...  \n",
      "82327    Normal\n",
      "82328    Normal\n",
      "82329    Normal\n",
      "82330    Normal\n",
      "82331    Normal\n",
      "Name: attack_cat, Length: 82332, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test_differences_state=list(set(train_state) - set(test_state))\n",
    "prefix_state = 'state_'\n",
    "test_differences=[prefix_state + x for x in test_differences_state]\n",
    "\n",
    "for differ in test_differences:\n",
    "    df_test_cat_data[differ] = 0\n",
    "\n",
    "new_df_train=df_train.join(df_train_cat_data)\n",
    "new_df_train.drop('state', axis=1, inplace=True)\n",
    "new_df_train.drop('proto', axis=1, inplace=True)\n",
    "new_df_train.drop('service', axis=1, inplace=True)\n",
    "new_df_train.drop('id', axis=1, inplace=True)\n",
    "# test data\n",
    "new_df_test=df_test.join(df_test_cat_data)\n",
    "new_df_test.drop('state', axis=1, inplace=True)\n",
    "new_df_test.drop('proto', axis=1, inplace=True)\n",
    "new_df_test.drop('service', axis=1, inplace=True)\n",
    "new_df_test.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# dif=list(set(new_df_train) - set(new_df_test))\n",
    "\n",
    "print(new_df_train['attack_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: attack_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "attack_df_train=new_df_train['attack_cat']\n",
    "attack_df_test=new_df_test['attack_cat']\n",
    "# change the label column\n",
    "new_attack_df_train=attack_df_train.replace({ 'Normal' : 0, 'Generic' : 1 ,'Exploits' : 2,'Fuzzers': 3,'DoS': 4,'Reconnaissance': 5,\n",
    "                            'Analysis' : 6,'Backdoor' : 7,'Shellcode' : 8,'Worms' : 9})\n",
    "new_attack_df_test=attack_df_test.replace({ 'Normal' : 0, 'Generic' : 1 ,'Exploits' : 2,'Fuzzers': 3,'DoS': 4,'Reconnaissance': 5,\n",
    "                            'Analysis' : 6,'Backdoor' : 7,'Shellcode' : 8,'Worms' : 9})\n",
    "# put the new label column back\n",
    "new_df_train['attack_cat'] = new_attack_df_train\n",
    "new_df_test['attack_cat'] = new_attack_df_test\n",
    "print(new_df_train['attack_cat'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_mask=new_df_train['attack_cat'] ==0\n",
    "attack_mask=new_df_train['attack_cat'] !=0\n",
    "\n",
    "# new_df_train.drop('attack_cat',axis=1,inplace=True)\n",
    "\n",
    "df_normal=new_df_train[normal_mask]\n",
    "df_attack=new_df_train[attack_mask]\n",
    "\n",
    "normal_mask_test=new_df_test['attack_cat'] ==0\n",
    "attack_mask_test=new_df_test['attack_cat'] !=0\n",
    "\n",
    "# new_df_train.drop('attack_cat',axis=1,inplace=True)\n",
    "\n",
    "df_normal_test=new_df_test[normal_mask_test]\n",
    "df_attack_test=new_df_test[attack_mask_test]\n",
    "\n",
    "\n",
    "print(df_normal_test.shape)\n",
    "print(df_attack_test.shape)\n",
    "\n",
    "# print(df_normal.shape)\n",
    "# print(df_attack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Dimensions of DoS: (63461, 198)\n",
      "Dimensions of Exploits: (71200, 198)\n",
      "Dimensions of Fuzzers: (76270, 198)\n",
      "Dimensions of DoS: (78243, 198)\n",
      "Dimensions of Reconnaissance: (78836, 198)\n",
      "Dimensions of Analysis: (81655, 198)\n",
      "Dimensions of Backdoor: (81749, 198)\n",
      "Dimensions of Shellcode: (81954, 198)\n",
      "Dimensions of Worms: (82288, 198)\n",
      "Test:\n",
      "Dimensions of DoS: (135341, 198)\n",
      "Dimensions of Exploits: (141948, 198)\n",
      "Dimensions of Fuzzers: (157157, 198)\n",
      "Dimensions of DoS: (163077, 198)\n",
      "Dimensions of Reconnaissance: (164850, 198)\n",
      "Dimensions of Analysis: (173341, 198)\n",
      "Dimensions of Backdoor: (173595, 198)\n",
      "Dimensions of Shellcode: (174208, 198)\n",
      "Dimensions of Worms: (175211, 198)\n"
     ]
    }
   ],
   "source": [
    "drop_Generic = [1]\n",
    "drop_Exploits = [2]\n",
    "drop_Fuzzers = [3]\n",
    "drop_DoS = [4]\n",
    "drop_Reconnaissance = [5]\n",
    "drop_Analysis = [6]\n",
    "drop_Backdoor = [7]\n",
    "drop_Shellcode = [8]\n",
    "drop_Worms = [9]\n",
    "\n",
    "Generic_df=new_df_train[~new_df_train['attack_cat'].isin(drop_Generic)];\n",
    "Exploits_df=new_df_train[~new_df_train['attack_cat'].isin(drop_Exploits)];\n",
    "Fuzzers_df=new_df_train[~new_df_train['attack_cat'].isin(drop_Fuzzers)];\n",
    "DoS_df=new_df_train[~new_df_train['attack_cat'].isin(drop_DoS)];\n",
    "Reconnaissance_df=new_df_train[~new_df_train['attack_cat'].isin(drop_Reconnaissance)];\n",
    "Analysis_df=new_df_train[~new_df_train['attack_cat'].isin(drop_Analysis)];\n",
    "Backdoor_df=new_df_train[~new_df_train['attack_cat'].isin(drop_Backdoor)];\n",
    "Shellcode_df=new_df_train[~new_df_train['attack_cat'].isin(drop_Shellcode)];\n",
    "Worms_df=new_df_train[~new_df_train['attack_cat'].isin(drop_Worms)];\n",
    "\n",
    "#test\n",
    "\n",
    "Generic_df_test=new_df_test[~new_df_test['attack_cat'].isin(drop_Generic)];\n",
    "Exploits_df_test=new_df_test[~new_df_test['attack_cat'].isin(drop_Exploits)];\n",
    "Fuzzers_df_test=new_df_test[~new_df_test['attack_cat'].isin(drop_Fuzzers)];\n",
    "DoS_df_test=new_df_test[~new_df_test['attack_cat'].isin(drop_DoS)];\n",
    "Reconnaissance_df_test=new_df_test[~new_df_test['attack_cat'].isin(drop_Reconnaissance)];\n",
    "Analysis_df_test=new_df_test[~new_df_test['attack_cat'].isin(drop_Analysis)];\n",
    "Backdoor_df_test=new_df_test[~new_df_test['attack_cat'].isin(drop_Backdoor)];\n",
    "Shellcode_df_test=new_df_test[~new_df_test['attack_cat'].isin(drop_Shellcode)];\n",
    "Worms_df_test=new_df_test[~new_df_test['attack_cat'].isin(drop_Worms)];\n",
    "\n",
    "print('Train:')\n",
    "\n",
    "print('Dimensions of DoS:' ,Generic_df.shape)\n",
    "print('Dimensions of Exploits:' ,Exploits_df.shape)\n",
    "print('Dimensions of Fuzzers:' ,Fuzzers_df.shape)\n",
    "print('Dimensions of DoS:' ,DoS_df.shape)\n",
    "print('Dimensions of Reconnaissance:' ,Reconnaissance_df.shape)\n",
    "print('Dimensions of Analysis:' ,Analysis_df.shape)\n",
    "print('Dimensions of Backdoor:' ,Backdoor_df.shape)\n",
    "print('Dimensions of Shellcode:' ,Shellcode_df.shape)\n",
    "print('Dimensions of Worms:' ,Worms_df.shape)\n",
    "\n",
    "print('Test:')\n",
    "print('Dimensions of DoS:' ,Generic_df_test.shape)\n",
    "print('Dimensions of Exploits:' ,Exploits_df_test.shape)\n",
    "print('Dimensions of Fuzzers:' ,Fuzzers_df_test.shape)\n",
    "print('Dimensions of DoS:' ,DoS_df_test.shape)\n",
    "print('Dimensions of Reconnaissance:' ,Reconnaissance_df_test.shape)\n",
    "print('Dimensions of Analysis:' ,Analysis_df_test.shape)\n",
    "print('Dimensions of Backdoor:' ,Backdoor_df_test.shape)\n",
    "print('Dimensions of Shellcode:' ,Shellcode_df_test.shape)\n",
    "print('Dimensions of Worms:' ,Worms_df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Generic = Generic_df.drop('attack_cat',1)\n",
    "Y_Generic = Generic_df.attack_cat\n",
    "\n",
    "X_Exploits = Exploits_df.drop('attack_cat',1)\n",
    "Y_Exploits = Exploits_df.attack_cat\n",
    "\n",
    "X_Fuzzers = Fuzzers_df.drop('attack_cat',1)\n",
    "Y_Fuzzers = Fuzzers_df.attack_cat\n",
    "\n",
    "X_DoS = DoS_df.drop('attack_cat',1)\n",
    "Y_DoS = DoS_df.attack_cat\n",
    "\n",
    "X_Reconnaissance = Reconnaissance_df.drop('attack_cat',1)\n",
    "Y_Reconnaissance = Reconnaissance_df.attack_cat\n",
    "\n",
    "X_Analysis = Analysis_df.drop('attack_cat',1)\n",
    "Y_Analysis = Analysis_df.attack_cat\n",
    "\n",
    "\n",
    "X_Backdoor = Backdoor_df.drop('attack_cat',1)\n",
    "Y_Backdoor = Backdoor_df.attack_cat\n",
    "\n",
    "\n",
    "X_Shellcode = Shellcode_df.drop('attack_cat',1)\n",
    "Y_Shellcode = Shellcode_df.attack_cat\n",
    "\n",
    "X_Worms =Worms_df.drop('attack_cat',1)\n",
    "Y_Worms =Worms_df.attack_cat\n",
    "\n",
    "X_Generic_test = Generic_df_test.drop('attack_cat',1)\n",
    "Y_Generic_test = Generic_df_test.attack_cat\n",
    "\n",
    "X_Exploits_test = Exploits_df_test.drop('attack_cat',1)\n",
    "Y_Exploits_test = Exploits_df_test.attack_cat\n",
    "\n",
    "X_Fuzzers_test = Fuzzers_df_test.drop('attack_cat',1)\n",
    "Y_Fuzzers_test = Fuzzers_df_test.attack_cat\n",
    "\n",
    "X_DoS_test = DoS_df_test.drop('attack_cat',1)\n",
    "Y_DoS_test = DoS_df_test.attack_cat\n",
    "\n",
    "X_Reconnaissance_test = Reconnaissance_df_test.drop('attack_cat',1)\n",
    "Y_Reconnaissance_test = Reconnaissance_df_test.attack_cat\n",
    "\n",
    "X_Analysis_test = Analysis_df_test.drop('attack_cat',1)\n",
    "Y_Analysis_test = Analysis_df_test.attack_cat\n",
    "\n",
    "\n",
    "X_Backdoor_test = Backdoor_df_test.drop('attack_cat',1)\n",
    "Y_Backdoor_test = Backdoor_df_test.attack_cat\n",
    "\n",
    "\n",
    "X_Shellcode_test = Shellcode_df_test.drop('attack_cat',1)\n",
    "Y_Shellcode_test = Shellcode_df_test.attack_cat\n",
    "\n",
    "X_Worms_test =Worms_df_test.drop('attack_cat',1)\n",
    "Y_Worms_test =Worms_df_test.attack_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normal=df_normal.drop('attack_cat',1)\n",
    "Y_normal=df_normal.attack_cat\n",
    "\n",
    "X_attack=df_attack.drop('attack_cat',1)\n",
    "Y_attack=df_attack.attack_cat\n",
    "\n",
    "X_normal_test=df_normal.drop('attack_cat',1)\n",
    "Y_normal_test=df_normal.attack_cat\n",
    "\n",
    "X_attack_test=df_attack.drop('attack_cat',1)\n",
    "Y_attack_test=df_attack.attack_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler1 = preprocessing.StandardScaler().fit(X_Generic)\n",
    "X_Generic=scaler1.transform(X_Generic)\n",
    "\n",
    "scaler2 = preprocessing.StandardScaler().fit(X_Generic_test)\n",
    "X_Generic_test=scaler2.transform(X_Generic_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_Generic.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler3 = preprocessing.StandardScaler().fit(X_Exploits)\n",
    "X_Exploits=scaler3.transform(X_Exploits)\n",
    "\n",
    "scaler4 = preprocessing.StandardScaler().fit(X_Exploits_test)\n",
    "X_Exploits_test=scaler4.transform(X_Exploits_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler5 = preprocessing.StandardScaler().fit(X_Fuzzers)\n",
    "X_Fuzzers=scaler5.transform(X_Fuzzers)\n",
    "\n",
    "scaler6= preprocessing.StandardScaler().fit(X_Fuzzers_test)\n",
    "X_Fuzzers_test=scaler6.transform(X_Fuzzers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler7 = preprocessing.StandardScaler().fit(X_DoS)\n",
    "X_DoS=scaler7.transform(X_DoS)\n",
    "\n",
    "scaler8 = preprocessing.StandardScaler().fit(X_DoS_test)\n",
    "X_DoS_test=scaler8.transform(X_DoS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler9 = preprocessing.StandardScaler().fit(X_Reconnaissance)\n",
    "X_Reconnaissance=scaler9.transform(X_Reconnaissance)\n",
    "\n",
    "scaler10 = preprocessing.StandardScaler().fit(X_Reconnaissance_test)\n",
    "X_Reconnaissance_test=scaler10.transform(X_Reconnaissance_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler11 = preprocessing.StandardScaler().fit(X_Analysis)\n",
    "X_Analysis=scaler11.transform(X_Analysis)\n",
    "\n",
    "scaler12 = preprocessing.StandardScaler().fit(X_Analysis_test)\n",
    "X_Analysis_test=scaler12.transform(X_Analysis_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler13 = preprocessing.StandardScaler().fit(X_Backdoor)\n",
    "X_Backdoor=scaler13.transform(X_Backdoor)\n",
    "\n",
    "scaler14 = preprocessing.StandardScaler().fit(X_Backdoor_test)\n",
    "X_Backdoor_test=scaler14.transform(X_Backdoor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler15 = preprocessing.StandardScaler().fit(X_Shellcode)\n",
    "X_Shellcode=scaler15.transform(X_Shellcode)\n",
    "\n",
    "scaler16 = preprocessing.StandardScaler().fit(X_Shellcode_test)\n",
    "X_Shellcode_test=scaler16.transform(X_Shellcode_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler17 = preprocessing.StandardScaler().fit(X_Worms)\n",
    "X_Worms=scaler17.transform(X_Worms)\n",
    "\n",
    "scaler18 = preprocessing.StandardScaler().fit(X_Worms_test)\n",
    "X_Worms_test=scaler18.transform(X_Worms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler19 = preprocessing.StandardScaler().fit(X_normal)\n",
    "X_normal=scaler19.transform(X_normal)\n",
    "\n",
    "scaler20 = preprocessing.StandardScaler().fit(X_normal_test)\n",
    "X_normal_test=scaler20.transform(X_normal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler21 = preprocessing.StandardScaler().fit(X_attack)\n",
    "X_attack=scaler21.transform(X_attack)\n",
    "\n",
    "scaler22 = preprocessing.StandardScaler().fit(X_attack_test)\n",
    "X_attack_test=scaler22.transform(X_attack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "rf_DoS = tree.DecisionTreeClassifier()\n",
    "rf_DoS.fit(X_DoS, Y_DoS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Generic=tree.DecisionTreeClassifier()\n",
    "rf_Generic.fit(X_Generic,Y_Generic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Exploits=tree.DecisionTreeClassifier()\n",
    "rf_Exploits.fit(X_Exploits,Y_Exploits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Fuzzers=tree.DecisionTreeClassifier()\n",
    "rf_Fuzzers.fit(X_Fuzzers,Y_Fuzzers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Analysis=tree.DecisionTreeClassifier()\n",
    "rf_Analysis.fit(X_Analysis,Y_Analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Backdoor=tree.DecisionTreeClassifier()\n",
    "rf_Backdoor.fit(X_Backdoor,Y_Backdoor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Shellcode=tree.DecisionTreeClassifier()\n",
    "rf_Shellcode.fit(X_Shellcode,Y_Shellcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Worms=tree.DecisionTreeClassifier()\n",
    "rf_Worms.fit(X_Worms,Y_Worms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Reconnaissance=tree.DecisionTreeClassifier()\n",
    "rf_Reconnaissance.fit(X_Reconnaissance,Y_Reconnaissance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_normal=tree.DecisionTreeClassifier()\n",
    "rf_normal.fit(X_normal,Y_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_attack=tree.DecisionTreeClassifier()\n",
    "rf_attack.fit(X_attack,Y_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_DoS.predict(X_DoS_test)\n",
    "rf_Generic.predict(X_Generic_test)\n",
    "rf_Exploits.predict(X_Exploits_test)\n",
    "rf_Fuzzers.predict(X_Fuzzers_test)\n",
    "rf_Analysis.predict(X_Analysis_test)\n",
    "rf_Backdoor.predict(X_Backdoor_test)\n",
    "rf_Shellcode.predict(X_Shellcode_test)\n",
    "rf_Worms.predict(X_Worms_test)\n",
    "rf_Reconnaissance.predict(X_Reconnaissance_test)\n",
    "rf_normal.predict(X_normal_test)\n",
    "rf_attack.predict(X_attack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_DoS_pred=rf_DoS.predict(X_DoS_test)\n",
    "Y_Generic_pred=rf_Generic.predict(X_Generic_test)\n",
    "Y_Exploits_pred=rf_Exploits.predict(X_Exploits_test)\n",
    "Y_Fuzzers_pred=rf_Fuzzers.predict(X_Fuzzers_test)\n",
    "Y_Analysis_pred=rf_Analysis.predict(X_Analysis_test)\n",
    "Y_Backdoor_pred=rf_Backdoor.predict(X_Backdoor_test)\n",
    "Y_Shellcode_pred=rf_Shellcode.predict(X_Shellcode_test)\n",
    "Y_Worms_pred=rf_Worms.predict(X_Worms_test)\n",
    "Y_Reconnaissance_pred=rf_Reconnaissance.predict(X_Reconnaissance_test)\n",
    "Y_normal_pred=rf_normal.predict(X_normal_test)\n",
    "Y_attack_pred=rf_attack.predict(X_attack_test)\n",
    "# Create confusion matrix\n",
    "# pd.crosstab(Y_DoS_test, Y_DoS_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_report(classifier,X,y,num_cv):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#   y_pred = cross_val_predict(classifier, X, y, cv=10)\n",
    "    scores = cross_val_score(classifier, X,y, cv=num_cv)\n",
    "    recall = cross_val_score(classifier, X, y, cv=num_cv, scoring='recall_weighted')\n",
    "    precision = cross_val_score(classifier, X, y, cv=num_cv, scoring='precision_weighted')\n",
    "    f1 = cross_val_score(classifier,X, y, scoring='f1_weighted', cv=num_cv)\n",
    "    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    print(\"Recall: %0.2f (+/- %0.2f)\" % (recall.mean(), recall.std() * 2))\n",
    "    print(\"Precision: %0.2f (+/- %0.2f)\" % (precision.mean(), precision.std() * 2))\n",
    "    print(\"F1-Score: %0.2f (+/- %0.2f)\" % (f1.mean(), f1.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93 (+/- 0.01)\n",
      "Recall: 0.93 (+/- 0.01)\n",
      "Precision: 0.92 (+/- 0.01)\n",
      "F1-Score: 0.92 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "DoS_accuracy=accuracy_report(rf_DoS,X_DoS_test,Y_DoS_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93 (+/- 0.02)\n",
      "Recall: 0.93 (+/- 0.02)\n",
      "Precision: 0.93 (+/- 0.02)\n",
      "F1-Score: 0.92 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "Exploits_accuracy=accuracy_report(rf_Exploits,X_Exploits_test,Y_Exploits_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.01)\n",
      "Recall: 0.85 (+/- 0.01)\n",
      "Precision: 0.85 (+/- 0.02)\n",
      "F1-Score: 0.85 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "Fuzzers_accuracy=accuracy_report(rf_Fuzzers,X_Fuzzers_test,Y_Fuzzers_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86 (+/- 0.02)\n",
      "Recall: 0.86 (+/- 0.02)\n",
      "Precision: 0.86 (+/- 0.01)\n",
      "F1-Score: 0.85 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "Analysis_accuracy=accuracy_report(rf_Analysis,X_Analysis_test,Y_Analysis_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86 (+/- 0.01)\n",
      "Recall: 0.86 (+/- 0.01)\n",
      "Precision: 0.86 (+/- 0.02)\n",
      "F1-Score: 0.85 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "Backdoor_accuracy=accuracy_report(rf_Backdoor,X_Backdoor_test,Y_Backdoor_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.01)\n",
      "Recall: 0.85 (+/- 0.01)\n",
      "Precision: 0.85 (+/- 0.02)\n",
      "F1-Score: 0.84 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "Worms_accuracy=accuracy_report(rf_Worms,X_Worms_test,Y_Worms_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86 (+/- 0.02)\n",
      "Recall: 0.86 (+/- 0.02)\n",
      "Precision: 0.86 (+/- 0.02)\n",
      "F1-Score: 0.85 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "Reconnaissance_accuracy=accuracy_report(rf_Reconnaissance,X_Reconnaissance_test,Y_Reconnaissance_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00 (+/- 0.00)\n",
      "Recall: 1.00 (+/- 0.00)\n",
      "Precision: 1.00 (+/- 0.00)\n",
      "F1-Score: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "Normal_accuracy=accuracy_report(rf_normal,X_normal_test,Y_normal_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashiu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ashiu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ashiu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ashiu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ashiu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ashiu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ashiu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ashiu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75 (+/- 0.06)\n",
      "Recall: 0.75 (+/- 0.06)\n",
      "Precision: 0.76 (+/- 0.06)\n",
      "F1-Score: 0.74 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "Attack_accuracy=accuracy_report(rf_attack,X_attack_test,Y_attack_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shellcode_accuracy=accuracy_report(rf_Shellcode,X_Shellcode_test,Y_Shellcode_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generic_accuracy=accuracy_report(rf_Generic,X_Generic_test,Y_Generic_test,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
